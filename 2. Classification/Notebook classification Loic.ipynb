{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#from roboflow import Roboflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    # Define device\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available. Using GPU.\")\n",
    "else:\n",
    "    # If GPU is not available, fall back to CPU\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rf = Roboflow(api_key=\"gJvPdZaOYF8eb2ctWoWS\")\\nproject = rf.workspace(\"ai-clinic-beekeeping\").project(\"beekeeping_step2\")\\nversion = project.version(4)\\ndataset = version.download(\"folder\")'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''rf = Roboflow(api_key=\"gJvPdZaOYF8eb2ctWoWS\")\n",
    "project = rf.workspace(\"ai-clinic-beekeeping\").project(\"beekeeping_step2\")\n",
    "version = project.version(4)\n",
    "dataset = version.download(\"folder\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPARE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 983 images belonging to 2 classes.\n",
      "Found 368 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset=\"beekeeping_step2-4\"\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset+'/train',  # This is the target directory\n",
    "    target_size=(410, 410),  # All images will be resized to 410x410\n",
    "    batch_size=32,\n",
    "    class_mode='binary')  # Since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "    dataset+'/valid',\n",
    "    target_size=(410, 410),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_tuner'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras_tuner'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "print(\"PIL imported successfully\")\n",
    "\n",
    "# Define the model building function\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    kernel_size_choice = hp.Choice('kernel_size', values=[3, 5])\n",
    "    kernel_size = (kernel_size_choice, kernel_size_choice)\n",
    "    activation_choice = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "    \n",
    "    # Adding filter choices for each Conv2D layer\n",
    "    filters_1 = hp.Choice('filters_1', values=[16, 32, 64])\n",
    "    filters_2 = hp.Choice('filters_2', values=[32, 64, 128])\n",
    "    filters_3 = hp.Choice('filters_3', values=[64, 128, 256])\n",
    "\n",
    "    model.add(Input(shape=(410, 410, 3)))  # Use Input layer here\n",
    "    model.add(Conv2D(filters_1, kernel_size, activation=activation_choice))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(filters_2, kernel_size, activation=activation_choice))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(filters_3, kernel_size, activation=activation_choice))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation=activation_choice))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define the dataset paths\n",
    "dataset = \"beekeeping_step2-4\"\n",
    "\n",
    "# ImageDataGenerator instances\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset+'/train',  # This is the target directory\n",
    "    target_size=(410, 410),  # All images will be resized to 410x410\n",
    "    batch_size=32,\n",
    "    class_mode='binary')  # Since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "    dataset+'/valid',\n",
    "    target_size=(410, 410),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "\n",
    "# Ensure the tuner directory is clean\n",
    "tuner_dir = 'my_dir'\n",
    "if os.path.exists(tuner_dir):\n",
    "    import shutil\n",
    "    shutil.rmtree(tuner_dir)\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    hyperband_iterations=1,\n",
    "    directory=tuner_dir,\n",
    "    project_name='beekeeping')\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True)\n",
    "\n",
    "# Run the hyperparameter search\n",
    "try:\n",
    "    print(\"Starting hyperparameter search...\")\n",
    "    tuner.search(\n",
    "        train_generator,\n",
    "        epochs=20,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[early_stopping])\n",
    "except Exception as e:\n",
    "    print(\"Error during hyperparameter tuning:\", e)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "try:\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    print(f\"\"\"\n",
    "    The hyperparameter search is complete. The optimal parameters are:\n",
    "    Activation function: {best_hps.get('activation')}\n",
    "    Kernel size: {best_hps.get('kernel_size')}\n",
    "    Filters for Conv2D layers: \n",
    "        Layer 1: {best_hps.get('filters_1')}\n",
    "        Layer 2: {best_hps.get('filters_2')}\n",
    "        Layer 3: {best_hps.get('filters_3')}\n",
    "    \"\"\")\n",
    "except Exception as e:\n",
    "    print(\"Error retrieving best hyperparameters:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = valid_datagen.flow_from_directory(\n",
    "    dataset+'/test',  # specify your test dataset directory\n",
    "    target_size=(410, 410),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "predictions = model.predict(test_generator)\n",
    "y_pred = np.round(predictions).astype(int).flatten()\n",
    "y_true = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the confusion matrix\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    print(cm)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8,8))\n",
    "plot_confusion_matrix(cm, classes=['Non-Pollen', 'Pollen'], normalize=False, title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the training and validation loss and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
